{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a simple Convolutional Neural Network to classify the MNIST dataset using TensorFlow\n",
    "\n",
    "Default settings:\n",
    "training epochs 12 \n",
    "training size 50000\n",
    "validation size 10000\n",
    "testset size 10000 \n",
    "\n",
    "leaning_rate 0.001\n",
    "num_filters 16\n",
    "batch_size 128\n",
    "filter_size 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(learning_curve, label='Learning Curve'):\n",
    "    plt.plot(learning_curve, label=label)\n",
    "    \n",
    "def plot_error_curve(error_curve, label='Error Curve'):\n",
    "    plt.plot(error_curve, label=label)\n",
    "\n",
    "\n",
    "def load_result(file_name):\n",
    "    with open(file_name) as data_file:\n",
    "        results = json.load(data_file)\n",
    "    learning_curve = [float(i) for i in results['learning_curve']]\n",
    "    error_curve = [1-float(i) for i in results['learning_curve']]\n",
    "    results.pop('learning_curve')\n",
    "    results['learning_curve'] = learning_curve\n",
    "    results['error_curve'] = error_curve\n",
    "    return results\n",
    "\n",
    "def create_accuracy_plot(run_ids, run_labels, title, saveName):\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(\"Accuracy on validation set\")\n",
    "    for run_id, run_label in zip(run_ids, run_labels):\n",
    "        file_name = 'results/results_run_{}.json'.format(run_id)\n",
    "        result = load_result(file_name)\n",
    "        plot_learning_curve(result['learning_curve'], run_label)\n",
    "    plt.legend()\n",
    "    plt.savefig(saveName)\n",
    "    plt.show()\n",
    "    \n",
    "def create_error_plot(run_ids, run_labels, title, saveName):\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(\"Validation error\")\n",
    "    for run_id, run_label in zip(run_ids, run_labels):\n",
    "        file_name = 'results/results_run_{}.json'.format(run_id)\n",
    "        result = load_result(file_name)\n",
    "        plot_error_curve(result['error_curve'], run_label)\n",
    "    plt.legend()\n",
    "    plt.savefig(saveName)\n",
    "    plt.show()\n",
    "    \n",
    "def run_configuration(run_id=0, batch_size=128, learning_rate=0.001, num_filters=16, filter_size=3):\n",
    "    # os.system('clear')\n",
    "    # os.system('rm tmp/mnist_convnet_model/*')\n",
    "    os.system('python3 cnn_mnist_amadeus.py --run_id={0} --batch_size={1} --learning_rate={2}\\\n",
    "              --num_filters={3} --filter_size={4}'.format(run_id, batch_size, learning_rate, num_filters, filter_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the default network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_configuration(run_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_accuracy_plot([0],[\"default settings, batch size 128\"], 'Learning Curve the default network', \"Learning_curve_default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_configuration(run_id=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = [0]\n",
    "run_labels = ['default settings, batch size 64']\n",
    "title = 'Learning Curve the default network with smaller batch size: 64'\n",
    "file_name = \"Learning_curve_default_bs_64\"\n",
    "\n",
    "create_accuracy_plot(run_ids, run_labels, title, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_configuration(run_id=11, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Learning Curve the default network with smaller batch size: 32')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "file_name = 'results/results_run_{}.json'.format(11)\n",
    "result = load_result(file_name)\n",
    "plot_learning_curve(result['learning_curve'], 'default settings, batch size 32')\n",
    "plt.legend()\n",
    "plt.savefig(\"Learning_curve_default_bs_32\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_configuration(run_id=12, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Learning Curve the default network with smaller batch size: 16')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "file_name = 'results/results_run_{}.json'.format(12)\n",
    "result = load_result(file_name)\n",
    "plot_learning_curve(result['learning_curve'], 'default settings, batch size 32')\n",
    "plt.legend()\n",
    "plt.savefig(\"Learning_curve_default_bs_16\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_configuration(run_id=13, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Learning Curve the default network with smaller batch size: 8')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "file_name = 'results/results_run_{}.json'.format(13)\n",
    "result = load_result(file_name)\n",
    "plot_learning_curve(result['learning_curve'], 'default settings, batch size 32')\n",
    "plt.legend()\n",
    "plt.savefig(\"Learning_curve_default_bs_8\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = [0,10,11,12,13]\n",
    "batch_sizes = [128, 64, 32, 16, 8]\n",
    "for run_id, batch_size in zip(run_ids, batch_sizes):\n",
    "    run_configuration(run_id, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = [0,10,11,12,13]\n",
    "run_labels = [\"128\", \"64\", \"32\", \"16\", \"8\"]\n",
    "\n",
    "title = 'Learning Curve for different batch sizes between 8 and 128'\n",
    "file_name = \"Learning_curve_for_Batch_Sizes\"\n",
    "create_accuracy_plot(run_ids, run_labels, title, file_name)\n",
    "\n",
    "title = 'Error Curve for different batch sizes between 8 and 128'\n",
    "file_name = \"Error_curve_for_Batch_Sizes\"\n",
    "create_error_plot(run_ids, run_labels, title, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Experiments\n",
    "\n",
    "Let the training run for 12 epoch with 4 different learning rate settings: (0.1, 0.01, 0.001, 0.0001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "\n",
    "run_ids = [5021, 5022, 5023, 5024]\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
    "for run_id, learning_rate in zip(run_ids, learning_rates):\n",
    "    time1 = time.time()\n",
    "    run_configuration(run_id=run_id, learning_rate=learning_rate)\n",
    "    print(\"This took: \", time.time()-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = [5021,5022,5023,5024]\n",
    "run_labels = [\"0.1\", \"0.01\", \"0.001\", \"0.0001\"]\n",
    "\n",
    "title = 'Learning Curve for different Learning Rates between 0.1 and 0.0001'\n",
    "file_name = \"Learning_curve_for_Learning_Rates\"\n",
    "create_accuracy_plot(run_ids, run_labels, title, file_name)\n",
    "\n",
    "title = 'Error Curve for different Learning Rates between 0.1 and 0.0001'\n",
    "file_name = \"Error_curve_for_Learning_Rates\"\n",
    "create_error_plot(run_ids, run_labels, title, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Size Experiments\n",
    "Let the training run for 12 epochs with 4 different filter_sizes: 1, 3, 5, 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = [5031, 5032, 5033, 5034]\n",
    "filter_sizes = [1, 3, 5, 7]\n",
    "for run_id, filter_size in zip(run_ids, filter_sizes):\n",
    "    run_configuration(run_id=run_id, filter_size=filter_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = [5031, 5032, 5033, 5034]\n",
    "filter_sizes = [1, 3, 5, 7]\n",
    "\n",
    "title = 'Learning Curve for different Filter Sizes between 1 and 7'\n",
    "file_name = 'Learning_curve_for_Filter_Sizes'\n",
    "create_accuracy_plot(run_ids, filter_sizes, title, file_name)\n",
    "\n",
    "title = 'Error Curve for different Filter Sizes between 1 and 7'\n",
    "file_name = 'Error_curve_for_Filter_Sizes'\n",
    "create_error_plot(run_ids, filter_sizes, title, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from hpbandster.core.result import Run\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "from operator import *\n",
    "\n",
    "\n",
    "with open('results/ah_allruns_results_run_9999.json', 'r') as fh:\n",
    "    all_runs_serialized = json.load(fh)\n",
    "\n",
    "all_runs_sorted = OrderedDict(sorted(all_runs_serialized.items(), key=lambda x: getitem(x[1], 'config_id')))\n",
    "all_runs = []\n",
    "\n",
    "for i, v in all_runs_serialized.items():\n",
    "    r = Run(config_id=v['config_id'],\n",
    "            budget=v['budget'],\n",
    "            loss=v['loss'],\n",
    "            info=v['info'],\n",
    "            time_stamps=v['time_stamps'],\n",
    "            error_logs=None\n",
    "            )\n",
    "    all_runs.append(r)\n",
    "    \n",
    "\n",
    "# Compare source of:\n",
    "#     import hpbandster.visualization as hpvis\n",
    "#     hpvis.losses_over_time(all_runs)\n",
    "import matplotlib.pyplot as plt\n",
    "get_loss_from_run_fn = lambda r: r.loss\n",
    "budgets = set([r.budget for r in all_runs])\n",
    "data = {}\n",
    "for b in budgets:\n",
    "    data[b] = []\n",
    "for i, r in enumerate(all_runs):\n",
    "    if r.loss is None:\n",
    "        continue\n",
    "    b = r.budget\n",
    "    # t = r.time_stamps['finished']\n",
    "    l = get_loss_from_run_fn(r)\n",
    "    t = i\n",
    "    data[b].append((t,l))\n",
    "\n",
    "for b in budgets:\n",
    "    data[b].sort()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, b in enumerate(budgets):\n",
    "    data[b] = np.array(data[b])\n",
    "    ax.scatter(range(1, len(data[b][:,0])+1), data[b][:,1], label='data')\n",
    "    \n",
    "    ax.step(range(1, len(data[b][:,0])+1), np.minimum.accumulate(data[b][:,1]), where='post')\n",
    "\n",
    "ax.set_title('Validation errors over the different iterations')\n",
    "ax.set_xlabel('iteration')\n",
    "ax.set_ylabel('validation error')\n",
    "plt.xlim(0, len(data[b][:,0])+1)\n",
    "ax.legend()\n",
    "plt.savefig(\"ah_random_search.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
